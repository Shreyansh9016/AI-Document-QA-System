# ğŸ“„ Chat with Your PDF â€” RAG App

An AI-powered web application that allows users to upload a PDF document and ask questions about its content using **Retrieval-Augmented Generation (RAG)**.

Built with **Streamlit, LangChain, FAISS, HuggingFace Embeddings, and Groq LLM (LLaMA 3.1)**.

---

## ğŸŒ Live Demo

ğŸš€ **Try the App Here:**  
ğŸ‘‰ https://ai-document-app-system-wggkmig7xhynefhmnmgkww.streamlit.app/

Upload any PDF â†’ Ask questions â†’ Get context-grounded answers instantly.

---

## âœ¨ Features

- ğŸ“‚ Upload any PDF document
- ğŸ” Semantic search using vector embeddings
- ğŸ§  Retrieval-Augmented Generation (RAG)
- âš¡ Fast inference using Groq LLaMA-3.1
- ğŸ“š Context-aware answers (minimized hallucinations)
- ğŸŒ Clean web interface with Streamlit
- ğŸ”’ Secure API key handling via environment variables

---

## ğŸ—ï¸ Tech Stack

- **Frontend/UI:** Streamlit  
- **PDF Processing:** PyPDF2  
- **Text Splitting:** LangChain Text Splitters  
- **Embeddings:** HuggingFace (MiniLM-L6-v2)  
- **Vector Database:** FAISS  
- **LLM:** Groq â€” LLaMA 3.1 8B Instant  
- **Language:** Python  

---

## ğŸ§  How It Works (RAG Pipeline)

1. User uploads a PDF  
2. Text is extracted from the document  
3. Text is split into chunks  
4. Each chunk is converted into vector embeddings  
5. Embeddings are stored in FAISS  
6. User asks a question  
7. Relevant chunks are retrieved  
8. LLM generates answer using ONLY retrieved context  

---

